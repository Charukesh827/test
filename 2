import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from sklearn.model_selection import train_test_split

# Load the dataset
data = pd.read_csv('/content/sample_data/DIABETICS DATASET.csv')

# # Calculate the correlation matrix and get the attributes most correlated to the Outcome
# correlation_matrix = data.corr()
# correlated_features = correlation_matrix["Outcome"].abs().sort_values(ascending=False)
# top_features = correlated_features.index[1:4]  # Select top 3 features (you can adjust the number)

# # Print top features
# print(f"Top correlated features: {list(top_features)}")

top_features=['Glucose', 'BMI']

# Create feature matrix X and target vector y
X = data[top_features].values
y = data['Outcome'].values

# Under-sampling for balancing the number of zero and one outcomes
class_0 = data[data["Outcome"] == 0]
class_1 = data[data["Outcome"] == 1]
class_0 = class_0.sample(n=len(class_1), random_state=42)
data_balanced = pd.concat([class_0, class_1])

X = data_balanced[top_features].values
y = data_balanced['Outcome'].values

print(Counter(y))

# Split the data using sklearn's train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# --- Logistic Regression Implementation ---

# Sigmoid function
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Cost function (binary cross-entropy)
def cost_function(X, y, theta):
    m = len(y)
    h = sigmoid(X @ theta)
    epsilon = 1e-15  # Small constant to prevent log(0)
    cost = (1/m) * (-y.T @ np.log(h + epsilon) - (1-y).T @ np.log(1-h + epsilon))
    return cost

# Gradient descent
def gradient_descent(X, y, theta, learning_rate, num_iterations):
    m = len(y)
    cost_history = []
    for i in range(num_iterations):
        h = sigmoid(X @ theta)
        gradient = (1/m) * X.T @ (h - y)
        theta -= learning_rate * gradient
        cost = cost_function(X, y, theta)
        cost_history.append(cost)
    return theta, cost_history

# Add a bias term to the features
X_train = np.c_[np.ones(X_train.shape[0]), X_train]

# Initialize parameters
theta = np.zeros(X_train.shape[1])

# Set hyperparameters
learning_rate = 0.01
num_iterations = 1000

# Perform gradient descent
theta, cost_history = gradient_descent(X_train, y_train, theta, learning_rate, num_iterations)

# Print the learned parameters
print("Learned parameters (theta):", theta)

# Predicting on test set
X_test_bias = np.c_[np.ones(X_test.shape[0]), X_test]
y_predict = sigmoid(X_test_bias @ theta)
y_pred = (y_predict >= 0.5).astype(int)

print(y_pred)

# Manual confusion matrix
def confusion_matrix_manual(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))
    return np.array([[tn, fp], [fn, tp]])

cm = confusion_matrix_manual(y_test, y_pred)
print("Confusion Matrix:\n", cm)

# Calculate accuracy manually
accuracy = np.sum(y_test == y_pred) / len(y_test)
print("Accuracy:", accuracy)

# Plot the cost function over iterations
plt.plot(range(num_iterations), cost_history)
plt.xlabel('Iterations')
plt.ylabel('Cost')
plt.title('Cost Function Over Iterations')
plt.show()
